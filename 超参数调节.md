# GRU超参数调节记录

##基本设置

- 迭代次数：50

  RNN(
    (rnn): GRU(66, 256, num_layers=2, batch_first=True, dropout=0.5)
    (out): Linear(in_features=256, out_features=66, bias=True)
  )

指标是最后3次在训练集上和验证集上的loss。

## 1. 有无mask

输入参数中是否应该包含mask？

- > 0.00026 0.00460 [包括]
  >

  0.00022 0.00442

  0.00021 0.00450 

- 0.00021 0.00404 [不包括]
  0.00020 0.00410
  0.00020 0.00407

结论：有mask会导致输入参数过多，训练难度增加啊，因而loss增加。

取消mask。

###2. LOSS设置

在loss中，为缺失部分增加权重。

参数weight表示，缺失部分所占的额外权重。

- weight=1

> 0.00012 0.00250
> 0.00011 0.00246
> 0.00011 0.00242     

- weight=0.5

> 0.00014  0.00317<br/>0.00016  0.00314
> 0.00016  0.00312

- weight=0

> 0.00026  0.00460<br/>0.00022  0.00442
> 0.00021  0.00450

结论，weight 也许应大些。

设为1。

## 3. 增加GRU层数

时间太长，故将迭代次数调整为20。

- 1层

> 0.00001 0.00018
> 0.00001 0.00018
> 0.00001 0.00017

- 2层

> 0.00017 0.00170
> 0.00014 0.00177
> 0.00013 0.00179

- 3层

> 0.00020 0.00322
> 0.00018 0.00332
> 0.00019 0.00339

- 4层

> 0.00031 0.00400
> 0.00026 0.00420
> 0.00029 0.00408

结论，保持2层。

### 4. dropout

迭代次数为 25

- dropout=0.5

> 0.00017 0.00170
> 0.00014 0.00177
> 0.00013 0.00179

- dropout=0.2

> 0.00007 0.00065
> 0.00005 0.00059
> 0.00008 0.00053

- dropout=0.1 

> 126.8s
>
> 0.00008 0.00048
> 0.00005 0.00045
> 0.00004 0.00047

- dropout=0

> 0.00001 0.00022
> 0.00001 0.00021
> 0.00001 0.00022

结论：dropout取较大的值，能够防止过拟合，但同时收敛的速度变慢。

dropout = 0 ，迭代次数250

> 248 300 0.000004 0.000099
> 249 300 0.000011 0.000069
> 250 300 0.000003 0.000063

## 5. 更改LOSS

LR = 5e-4

1:1 0:1

> 48 300 0.000016 0.000009
> 49 300 0.000005 0.000009
> 50 300 0.000011 0.000009

1:2 0:1

> 48 300 0.000005 0.000009
> 49 300 0.000005 0.000009
> 50 300 0.000004 0.000009

1:3

>  48 0.0000068 0.0000084
>  49 0.0000051 0.0000085
>  50 0.0000037 0.0000088

1:4

>  48 0.0000032 0.0000094
>  49 0.0000077 0.0000092
>  50 0.0000042 0.0000095

1:5 0:1

> 48 0.0000025 0.0000089
> 49 0.0000029 0.0000084
> 50 0.0000025 0.0000084

1:10

> 48 0.0000028 0.0000087
> 49 0.0000032 0.0000087
> 50 0.0000050 0.0000090

结论：取1:3。

> 154 0.0000020 0.0000060
> 155 0.0000021 0.0000057
> 156 0.0000022 0.0000055